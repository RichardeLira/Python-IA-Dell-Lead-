{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ignore\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rícharde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rícharde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from logging import warning\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import heapq\n",
    "import string\n",
    "# NLP tools\n",
    "import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "# Machine Learning Models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes  import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Hold out / Grid / Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Metrics \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "# .Config \n",
    "warning(\"ignore\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilize o arquivo moviesreviews.tsv (sep = ‘\\t’)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv(r\"C:\\Users\\Rícharde\\Documents\\Dell lead\\Atividade 06\\moviereviews.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neg</td>\n",
       "      <td>to put it bluntly , ed wood would have been pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neg</td>\n",
       "      <td>synopsis : melissa , a mentally-disturbed woma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neg</td>\n",
       "      <td>tim robbins and martin lawernce team up in thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neg</td>\n",
       "      <td>in \" gia \" , angelina jolie plays the titular ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neg</td>\n",
       "      <td>in 1990 , the surprise success an unheralded l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   neg  how do films like mouse hunt get into theatres...\n",
       "1   neg  some talented actresses are blessed with a dem...\n",
       "2   pos  this has been an extraordinary year for austra...\n",
       "3   pos  according to hollywood movies made in last few...\n",
       "4   neg  my first press screening of 1998 and already i...\n",
       "5   neg  to put it bluntly , ed wood would have been pr...\n",
       "6   neg  synopsis : melissa , a mentally-disturbed woma...\n",
       "7   neg  tim robbins and martin lawernce team up in thi...\n",
       "8   neg  in \" gia \" , angelina jolie plays the titular ...\n",
       "9   neg  in 1990 , the surprise success an unheralded l..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faça pré-processamento dos dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataSet analysys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   2000 non-null   object\n",
      " 1   review  1965 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "review    35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    1000\n",
       "pos    1000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label review\n",
       "140    pos    NaN\n",
       "208    pos    NaN\n",
       "270    neg    NaN\n",
       "334    neg    NaN\n",
       "448    neg    NaN\n",
       "522    neg    NaN\n",
       "606    pos    NaN\n",
       "696    neg    NaN\n",
       "728    pos    NaN\n",
       "738    neg    NaN\n",
       "744    pos    NaN\n",
       "786    pos    NaN\n",
       "820    pos    NaN\n",
       "866    neg    NaN\n",
       "986    neg    NaN\n",
       "1072   neg    NaN\n",
       "1156   pos    NaN\n",
       "1204   pos    NaN\n",
       "1260   neg    NaN\n",
       "1272   neg    NaN\n",
       "1294   neg    NaN\n",
       "1314   pos    NaN\n",
       "1330   neg    NaN\n",
       "1332   neg    NaN\n",
       "1426   pos    NaN\n",
       "1456   pos    NaN\n",
       "1486   pos    NaN\n",
       "1538   neg    NaN\n",
       "1568   neg    NaN\n",
       "1584   pos    NaN\n",
       "1588   pos    NaN\n",
       "1600   pos    NaN\n",
       "1662   pos    NaN\n",
       "1904   pos    NaN\n",
       "1908   neg    NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null values position\n",
    "# creating bool series True for NaN values \n",
    "bool_series = pd.isnull(reviews_df[\"review\"]) \n",
    "    \n",
    "# filtering data \n",
    "# displaying data only with Gender = NaN \n",
    "reviews_df[bool_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label     0\n",
      "review    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "reviews_df = reviews_df.dropna()\n",
    "print(reviews_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    983\n",
       "pos    982\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label transform \n",
    "data = LabelBinarizer().fit_transform(reviews_df[\"label\"])\n",
    "reviews_df[\"label\"] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenizing_Sentences(Data,colun_term):\n",
    "    sentences = Data[colun_term]\n",
    "    Iloc = 0\n",
    "    for sentece in sentences:\n",
    "        tonken_text = word_tokenize(sentece,language=\"english\",preserve_line=False)\n",
    "        Data[colun_term].iloc[Iloc] = tonken_text\n",
    "        Iloc+=1\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rícharde\\AppData\\Local\\Temp\\ipykernel_9936\\812245980.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data[colun_term].iloc[Iloc] = tonken_text\n"
     ]
    }
   ],
   "source": [
    "reviews_df = Tokenizing_Sentences(reviews_df,'review')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_Words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Verify_Stop_Words(sentence):\n",
    "    text = list(sentence)\n",
    "    for word in stop_Words:    \n",
    "        if text.__contains__(word):\n",
    "            text.remove(word)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rícharde\\AppData\\Local\\Temp\\ipykernel_9936\\80236415.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df[\"review\"].iloc[Iloc] = text\n"
     ]
    }
   ],
   "source": [
    "sentences = reviews_df[\"review\"]\n",
    "Iloc = 0\n",
    "for sentence in sentences:\n",
    "    text = Verify_Stop_Words(sentence)\n",
    "    reviews_df[\"review\"].iloc[Iloc] = text\n",
    "    Iloc +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Punctuation and special caracter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rícharde\\AppData\\Local\\Temp\\ipykernel_9936\\1056579119.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df[\"review\"].iloc[Iloc] = text\n"
     ]
    }
   ],
   "source": [
    "sentences = reviews_df[\"review\"]\n",
    "Iloc = 0                                                                                                                \n",
    "for sentence in sentences:\n",
    "    text = re.sub(r'[^\\w\\s]', '',str(sentence))\n",
    "    reviews_df[\"review\"].iloc[Iloc] = text\n",
    "    Iloc +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>films like mouse hunt get theatres  nt law som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>talented actresses blessed demonstrated wide a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>extraordinary year australian films   shine  h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>according hollywood movies made last decades  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>first press screening 1998 already ve gotten p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1</td>\n",
       "      <td>like movies albert brooks  i really like movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1</td>\n",
       "      <td>might surprise know joel ethan coen  brought u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1</td>\n",
       "      <td>verdict  spinechilling drama horror maestro st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1</td>\n",
       "      <td>want correct i wrote former retrospective davi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1</td>\n",
       "      <td>couple months ago  first downloaded faceoff tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1965 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             review\n",
       "0         0  films like mouse hunt get theatres  nt law som...\n",
       "1         0  talented actresses blessed demonstrated wide a...\n",
       "2         1  extraordinary year australian films   shine  h...\n",
       "3         1  according hollywood movies made last decades  ...\n",
       "4         0  first press screening 1998 already ve gotten p...\n",
       "...     ...                                                ...\n",
       "1995      1  like movies albert brooks  i really like movie...\n",
       "1996      1  might surprise know joel ethan coen  brought u...\n",
       "1997      1  verdict  spinechilling drama horror maestro st...\n",
       "1998      1  want correct i wrote former retrospective davi...\n",
       "1999      1  couple months ago  first downloaded faceoff tr...\n",
       "\n",
       "[1965 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separe os dados em treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data separation\n",
    "X = reviews_df[\"review\"]\n",
    "y = reviews_df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extração de características do texto utilizando BOW e TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(1,1))\n",
    "X_count   = count_vec.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfTransformer(norm=\"l1\")\n",
    "X_freq_count = tf.fit_transform(X_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classificação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models['kNN'] = KNeighborsClassifier(n_neighbors=3,n_jobs=-1)\n",
    "models['Random Forest'] = RandomForestClassifier(n_estimators=250,random_state=42)\n",
    "models['Naive Bayes'] = GaussianNB()\n",
    "models['MLP_1'] = MLPClassifier(hidden_layer_sizes=(30,),activation='relu')\n",
    "models['MLP_2'] = MLPClassifier(hidden_layer_sizes=(30,30),activation='relu')\n",
    "models['SVM'] = SVC()\n",
    "models['DT'] = DecisionTreeClassifier(random_state=42,min_samples_split=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_freq_count,y,test_size=0.8,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name   = []\n",
    "result_acc   = []\n",
    "result_f1    = []\n",
    "\n",
    "for actual_model in models.keys(): \n",
    "    __some_model__ = models[actual_model].fit(X_train.toarray(),y_train)\n",
    "    y_predict      = models[actual_model].predict(X_test.toarray())\n",
    "    # score test \n",
    "    acc_scr    = accuracy_score(y_test,y_predict)\n",
    "    f1_scr     = f1_score(y_test,y_predict,average='weighted')\n",
    "    # savaing information \n",
    "    model_name.append(str(actual_model))\n",
    "    result_acc.append(acc_scr)\n",
    "    result_f1.append(f1_scr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.506361</td>\n",
       "      <td>0.355240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.591603</td>\n",
       "      <td>0.591192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.611323</td>\n",
       "      <td>0.608609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.697201</td>\n",
       "      <td>0.695872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.725827</td>\n",
       "      <td>0.725583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP_1</td>\n",
       "      <td>0.772265</td>\n",
       "      <td>0.771449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP_2</td>\n",
       "      <td>0.775445</td>\n",
       "      <td>0.774692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model name  Accuracy  F1-Score\n",
       "0            kNN  0.506361  0.355240\n",
       "6             DT  0.591603  0.591192\n",
       "2    Naive Bayes  0.611323  0.608609\n",
       "5            SVM  0.697201  0.695872\n",
       "1  Random Forest  0.725827  0.725583\n",
       "3          MLP_1  0.772265  0.771449\n",
       "4          MLP_2  0.775445  0.774692"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'Model name': model_name, 'Accuracy':result_acc, 'F1-Score':result_f1})\n",
    "result = result.sort_values(by='Accuracy')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimize o Classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn model\n",
    "hyper_1 = {}\n",
    "hyper_1 ['classifier__n_neighbors'] = [3,9,18,25]\n",
    "hyper_1 ['classifier__leaf_size'] = [5,12,20]\n",
    "hyper_1 ['classifier__algorithm'] = ['ball_tree','kd_tree']\n",
    "hyper_1['classifier'] = [models['kNN']]\n",
    "# Random Forest model\n",
    "hyper_2 = {}\n",
    "hyper_2 ['classifier__n_estimators'] = [10,20,30,50,100,150,200]\n",
    "hyper_2 ['classifier__criterion'] = ['gini', 'entropy']\n",
    "hyper_2 ['classifier__max_depth'] = [5,20,50,80,100]\n",
    "hyper_2['classifier'] = [models['Random Forest']]\n",
    "# Naive Bayes modedl\n",
    "hyper_3 = {}\n",
    "hyper_3 ['classifier__var_smoothing'] = [0.00001,0.001,0.1]\n",
    "hyper_3['classifier'] = [models['Naive Bayes']]\n",
    "# MLP model 1\n",
    "hyper_4 = {}\n",
    "hyper_4 ['classifier__hidden_layer_sizes'] = [(20,),(50,),(100,)]\n",
    "hyper_4 ['classifier__activation'] = ['logistic','tanh','relu']\n",
    "hyper_4 ['classifier__alpha'] = [0000.1, 00.1, 1]\n",
    "hyper_4['classifier'] = [models['MLP_1']]\n",
    "# MLP model 2\n",
    "hyper_5 = {}\n",
    "hyper_5 ['classifier__hidden_layer_sizes'] = [(20,20),(50,50),(100,100)]\n",
    "hyper_5 ['classifier__activation'] = ['logistic','tanh','relu']\n",
    "hyper_5 ['classifier__alpha'] = [0000.1, 00.1, 1]\n",
    "hyper_5['classifier'] = [models['MLP_2']]\n",
    "# SVM model \n",
    "hyper_6 = {}\n",
    "hyper_6['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "hyper_6['classifier__kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "hyper_6['classifier__gamma'] = ['scale','auto']\n",
    "hyper_6['classifier'] = [models['SVM']]\n",
    "# Decision Tree Model\n",
    "hyper_7 = {}\n",
    "hyper_7['classifier__criterion'] = ['gini','entropy','log_loss']\n",
    "hyper_7['classifier__splitter'] = ['best', 'random']\n",
    "hyper_7['classifier__max_depth'] = [10,20,50,100]\n",
    "hyper_7['classifier__min_samples_split'] = [2,5,10,15,25]\n",
    "hyper_7['classifier'] = [models['DT']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('classifier', models['kNN'])])\n",
    "params = [hyper_1,hyper_2,hyper_3,hyper_4,hyper_5,hyper_6,hyper_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold  = KFold(n_splits=3,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridCV  = GridSearchCV(estimator=pipe,param_grid=params,cv=k_fold,n_jobs=-1,scoring='accuracy',return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "9 fits failed out of a total of 933.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 243, in fit\n",
      "    return self._partial_fit(\n",
      "  File \"c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 400, in _partial_fit\n",
      "    X, y = self._validate_data(X, y, reset=first_call)\n",
      "  File \"c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 822, in check_array\n",
      "    array = _ensure_sparse_format(\n",
      "  File \"c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 512, in _ensure_sparse_format\n",
      "    raise TypeError(\n",
      "TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.65998807 0.6907573  0.67274896 0.68294574 0.65998807 0.6907573\n",
      " 0.67274896 0.68294574 0.65998807 0.6907573  0.67274896 0.68294574\n",
      " 0.65998807 0.6907573  0.67274896 0.68294574 0.65998807 0.6907573\n",
      " 0.67274896 0.68294574 0.65998807 0.6907573  0.67274896 0.68294574\n",
      " 0.57201352 0.61071358 0.64951302 0.63925661 0.65476048 0.67278871\n",
      " 0.67276883 0.6132578  0.63647386 0.64172133 0.67274896 0.69344067\n",
      " 0.69858875 0.70886504 0.59779368 0.63647386 0.636613   0.70103359\n",
      " 0.68556947 0.69844961 0.69846949 0.59779368 0.63647386 0.636613\n",
      " 0.70103359 0.68556947 0.69844961 0.69846949 0.59779368 0.63647386\n",
      " 0.636613   0.70103359 0.68556947 0.69844961 0.69846949 0.60824886\n",
      " 0.64692904 0.63925661 0.66241304 0.67276883 0.67785728 0.66760087\n",
      " 0.60822898 0.62371298 0.67274896 0.66750149 0.69848937 0.70608229\n",
      " 0.71898231 0.58240906 0.63390976 0.67008547 0.68821308 0.70099384\n",
      " 0.72158617 0.72935798 0.58240906 0.63390976 0.67008547 0.68821308\n",
      " 0.70099384 0.72158617 0.72935798 0.58240906 0.63390976 0.67008547\n",
      " 0.68821308 0.70099384 0.72158617 0.72935798        nan        nan\n",
      "        nan 0.61613993 0.65988869 0.59035977 0.561936   0.71136951\n",
      " 0.69594514 0.4715961  0.4715961  0.4715961  0.76557344 0.76044524\n",
      " 0.76300934 0.7681773  0.75784138 0.76557344 0.75527728 0.75784138\n",
      " 0.76302922 0.77328563 0.76815742 0.7707414  0.77332538 0.76815742\n",
      " 0.76042536 0.76046512 0.7552574  0.74494136 0.4715961  0.4715961\n",
      " 0.4715961  0.4715961  0.4715961  0.57753926 0.4715961  0.4715961\n",
      " 0.4715961  0.76302922 0.76300934 0.76300934 0.7681773  0.7681773\n",
      " 0.76302922 0.7681773  0.77076128 0.7552574  0.76042536 0.77076128\n",
      " 0.76557344 0.76559332 0.76044524 0.76557344 0.76815742 0.75786126\n",
      " 0.76559332 0.4715961  0.4715961  0.4715961  0.4715961  0.4715961\n",
      " 0.4715961  0.4715961  0.4715961  0.4715961  0.4715961  0.4715961\n",
      " 0.4715961  0.4715961  0.4715961  0.4715961  0.4715961  0.76042536\n",
      " 0.51031604 0.59797257 0.75523753 0.76042536 0.4715961  0.4715961\n",
      " 0.4715961  0.77076128 0.51290002 0.75527728 0.77076128 0.77076128\n",
      " 0.4715961  0.4715961  0.4715961  0.77076128 0.51290002 0.75527728\n",
      " 0.77076128 0.77076128 0.4715961  0.4715961  0.4715961  0.63901809\n",
      " 0.60314053 0.63901809 0.61083284 0.64170145 0.60824886 0.62878155\n",
      " 0.60568475 0.64426555 0.60822898 0.67002584 0.62627708 0.67260982\n",
      " 0.61345657 0.64170145 0.62635659 0.63911747 0.61343669 0.65718545\n",
      " 0.63144504 0.67002584 0.6236931  0.67260982 0.61604055 0.64170145\n",
      " 0.61860465 0.63911747 0.62118863 0.65718545 0.636613   0.67002584\n",
      " 0.6236931  0.67260982 0.61604055 0.64170145 0.61860465 0.63911747\n",
      " 0.62118863 0.65718545 0.636613   0.61598092 0.63915723 0.61598092\n",
      " 0.6417412  0.6185649  0.64176108 0.61333731 0.64432518 0.61848539\n",
      " 0.64945339 0.6082091  0.66485788 0.6082091  0.66740211 0.61337706\n",
      " 0.65706619 0.61073345 0.64935401 0.62365335 0.65961042 0.6082091\n",
      " 0.64935401 0.6082091  0.65965017 0.61337706 0.64931425 0.61073345\n",
      " 0.65452196 0.62365335 0.66219439 0.6082091  0.64935401 0.6082091\n",
      " 0.65965017 0.61337706 0.64931425 0.61073345 0.65452196 0.62365335\n",
      " 0.66219439 0.61598092 0.63915723 0.61598092 0.6417412  0.6185649\n",
      " 0.64176108 0.61333731 0.64432518 0.61848539 0.64945339 0.6082091\n",
      " 0.66485788 0.6082091  0.66740211 0.61337706 0.65706619 0.61073345\n",
      " 0.64935401 0.62365335 0.65961042 0.6082091  0.64935401 0.6082091\n",
      " 0.65965017 0.61337706 0.64931425 0.61073345 0.65452196 0.62365335\n",
      " 0.66219439 0.6082091  0.64935401 0.6082091  0.65965017 0.61337706\n",
      " 0.64931425 0.61073345 0.65452196 0.62365335 0.66219439]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.81572935 0.76159548 0.7126595  0.73971147 0.81572935 0.76159548\n",
      " 0.7126595  0.73971147 0.81572935 0.76159548 0.7126595  0.73971147\n",
      " 0.81572935 0.76159548 0.7126595  0.73971147 0.81572935 0.76159548\n",
      " 0.7126595  0.73971147 0.81572935 0.76159548 0.7126595  0.73971147\n",
      " 0.84537029 0.9072112  0.93167919 0.95100416 0.97035408 0.97938803\n",
      " 0.98454601 0.98067503 0.99356001 0.99613401 0.99742101 0.99870801\n",
      " 0.99742101 0.99742101 0.98712001 1.         1.         1.\n",
      " 1.         1.         1.         0.98712001 1.         1.\n",
      " 1.         1.         1.         1.         0.98712001 1.\n",
      " 1.         1.         1.         1.         1.         0.82730737\n",
      " 0.88658925 0.92007622 0.94585117 0.96905211 0.97551206 0.97937805\n",
      " 0.97164108 0.99097603 0.99355502 0.99613401 0.99742101 0.99742101\n",
      " 0.99870801 0.98068002 0.997426   1.         1.         1.\n",
      " 1.         1.         0.98068002 0.997426   1.         1.\n",
      " 1.         1.         1.         0.98068002 0.997426   1.\n",
      " 1.         1.         1.         1.                nan        nan\n",
      "        nan 0.98840701 0.99484701 0.98839703 0.98453104 0.99870801\n",
      " 0.99484701 0.51932996 0.51932996 0.56437501 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.51932996 0.51932996\n",
      " 0.51932996 0.51932996 0.51932996 0.67891812 0.51932996 0.51932996\n",
      " 0.51932996 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.51932996 0.51932996 0.51932996 0.51932996 0.51932996\n",
      " 0.51932996 0.51932996 0.51932996 0.51932996 0.51932996 0.51932996\n",
      " 0.51932996 0.51932996 0.51932996 0.51932996 0.51932996 1.\n",
      " 1.         1.         0.99098101 1.         0.51932996 0.51932996\n",
      " 0.51932996 1.         1.         1.         1.         1.\n",
      " 0.51932996 0.51932996 0.51932996 1.         1.         1.\n",
      " 1.         1.         0.51932996 0.51932996 0.51932996 0.98584299\n",
      " 0.86602217 0.98197699 0.86344318 0.969097   0.86086917 0.961375\n",
      " 0.85312223 0.93045704 0.84150429 1.         0.99485199 0.992273\n",
      " 0.98454601 0.97939301 0.97552203 0.97295801 0.96520108 0.94075305\n",
      " 0.94714814 1.         1.         0.992273   0.99098101 0.97939301\n",
      " 0.98195704 0.97295801 0.97163609 0.94075305 0.95100915 1.\n",
      " 1.         0.992273   0.99098101 0.97939301 0.98195704 0.97295801\n",
      " 0.97163609 0.94075305 0.95100915 0.96781998 0.86856624 0.96781998\n",
      " 0.86599224 0.961375   0.86212625 0.93429809 0.8556663  0.91367613\n",
      " 0.84923129 1.         0.996139   1.         0.989699   0.98197201\n",
      " 0.97554199 0.94588609 0.96135504 0.92011613 0.94200014 1.\n",
      " 1.         1.         0.99484701 0.98197201 0.984551   0.94588609\n",
      " 0.96521605 0.92011613 0.94586114 1.         1.         1.\n",
      " 0.99484701 0.98197201 0.984551   0.94588609 0.96521605 0.92011613\n",
      " 0.94586114 0.96781998 0.86856624 0.96781998 0.86599224 0.961375\n",
      " 0.86212625 0.93429809 0.8556663  0.91367613 0.84923129 1.\n",
      " 0.996139   1.         0.989699   0.98197201 0.97554199 0.94588609\n",
      " 0.96135504 0.92011613 0.94200014 1.         1.         1.\n",
      " 0.99484701 0.98197201 0.984551   0.94588609 0.96521605 0.92011613\n",
      " 0.94586114 1.         1.         1.         0.99484701 0.98197201\n",
      " 0.984551   0.94588609 0.96521605 0.92011613 0.94586114]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 39.9 s\n",
      "Wall time: 55min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;classifier&#x27;,\n",
       "                                        KNeighborsClassifier(n_jobs=-1,\n",
       "                                                             n_neighbors=3))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;classifier&#x27;: [KNeighborsClassifier(n_jobs=-1,\n",
       "                                                              n_neighbors=3)],\n",
       "                          &#x27;classifier__algorithm&#x27;: [&#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;],\n",
       "                          &#x27;classifier__leaf_size&#x27;: [5, 12, 20],\n",
       "                          &#x27;classifier__n_neighbors&#x27;: [3, 9, 1...\n",
       "                          &#x27;classifier__kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;,\n",
       "                                                 &#x27;sigmoid&#x27;]},\n",
       "                         {&#x27;classifier&#x27;: [DecisionTreeClassifier(min_samples_split=10,\n",
       "                                                                random_state=42)],\n",
       "                          &#x27;classifier__criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;,\n",
       "                                                    &#x27;log_loss&#x27;],\n",
       "                          &#x27;classifier__max_depth&#x27;: [10, 20, 50, 100],\n",
       "                          &#x27;classifier__min_samples_split&#x27;: [2, 5, 10, 15, 25],\n",
       "                          &#x27;classifier__splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]}],\n",
       "             return_train_score=True, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;classifier&#x27;,\n",
       "                                        KNeighborsClassifier(n_jobs=-1,\n",
       "                                                             n_neighbors=3))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;classifier&#x27;: [KNeighborsClassifier(n_jobs=-1,\n",
       "                                                              n_neighbors=3)],\n",
       "                          &#x27;classifier__algorithm&#x27;: [&#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;],\n",
       "                          &#x27;classifier__leaf_size&#x27;: [5, 12, 20],\n",
       "                          &#x27;classifier__n_neighbors&#x27;: [3, 9, 1...\n",
       "                          &#x27;classifier__kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;,\n",
       "                                                 &#x27;sigmoid&#x27;]},\n",
       "                         {&#x27;classifier&#x27;: [DecisionTreeClassifier(min_samples_split=10,\n",
       "                                                                random_state=42)],\n",
       "                          &#x27;classifier__criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;,\n",
       "                                                    &#x27;log_loss&#x27;],\n",
       "                          &#x27;classifier__max_depth&#x27;: [10, 20, 50, 100],\n",
       "                          &#x27;classifier__min_samples_split&#x27;: [2, 5, 10, 15, 25],\n",
       "                          &#x27;classifier__splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]}],\n",
       "             return_train_score=True, scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;, KNeighborsClassifier(n_jobs=-1, n_neighbors=3))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_jobs=-1, n_neighbors=3)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('classifier',\n",
       "                                        KNeighborsClassifier(n_jobs=-1,\n",
       "                                                             n_neighbors=3))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'classifier': [KNeighborsClassifier(n_jobs=-1,\n",
       "                                                              n_neighbors=3)],\n",
       "                          'classifier__algorithm': ['ball_tree', 'kd_tree'],\n",
       "                          'classifier__leaf_size': [5, 12, 20],\n",
       "                          'classifier__n_neighbors': [3, 9, 1...\n",
       "                          'classifier__kernel': ['linear', 'poly', 'rbf',\n",
       "                                                 'sigmoid']},\n",
       "                         {'classifier': [DecisionTreeClassifier(min_samples_split=10,\n",
       "                                                                random_state=42)],\n",
       "                          'classifier__criterion': ['gini', 'entropy',\n",
       "                                                    'log_loss'],\n",
       "                          'classifier__max_depth': [10, 20, 50, 100],\n",
       "                          'classifier__min_samples_split': [2, 5, 10, 15, 25],\n",
       "                          'classifier__splitter': ['best', 'random']}],\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gridCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': MLPClassifier(alpha=0.1, hidden_layer_sizes=(20,)),\n",
       " 'classifier__activation': 'relu',\n",
       " 'classifier__alpha': 0.1,\n",
       " 'classifier__hidden_layer_sizes': (20,)}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best performing model and its corresponding hyperparameters\n",
    "gridCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7733253826277083"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridCV.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste novos pré-processamentos e verifique se há melhora nos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv(r\"C:\\Users\\Rícharde\\Documents\\Dell lead\\Atividade 06\\moviereviews.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Frame preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = reviews_df.drop_duplicates()\n",
    "reviews_df=reviews_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label transform \n",
    "data = LabelBinarizer().fit_transform(reviews_df[\"label\"])\n",
    "reviews_df[\"label\"] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1940 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   1940 non-null   int32 \n",
      " 1   review  1940 non-null   object\n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 37.9+ KB\n"
     ]
    }
   ],
   "source": [
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nlp preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(sentence):\n",
    "    expanded_words = []   \n",
    "    for word in sentence.split():\n",
    "        expanded_words.append(contractions.fix(word))  \n",
    "    return ' '.join(expanded_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove links,dots,commas,numbers \n",
    "def clean_text(instance):\n",
    "    instance = instance.lower()\n",
    "    instance = re.sub('\\[.*?\\]', ' ', instance)\n",
    "    instance = re.sub('https?://\\S+|www\\.\\S+', ' ', instance)\n",
    "    instance = re.sub('<.*?>+', ' ', instance)\n",
    "    instance = re.sub('[%s]' % re.escape(string.punctuation), ' ', instance)\n",
    "    instance = re.sub('\\n', '', instance)\n",
    "    instance = re.sub('\\w*\\d\\w*', ' ', instance)\n",
    "    return instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveStopWords(instance):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    palavras = [i for i in instance.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def Lemmatization(instancia):\n",
    "  palavras = []\n",
    "  for w in instancia.split():\n",
    "    palavras.append(wordnet_lemmatizer.lemmatize(w))\n",
    "  return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Extra Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(instance):\n",
    "    instance = re.sub(' +', ' ', instance)\n",
    "    return instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running new preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(df,local_data):\n",
    "    df[local_data] = df[local_data].apply(lambda local_data: expand_contractions(local_data))\n",
    "    df[local_data] = df[local_data].apply(lambda local_data: lower_case(local_data))\n",
    "    df[local_data] = df[local_data].apply(lambda local_data: clean_text(local_data))\n",
    "    df[local_data] = df[local_data].apply(lambda local_data: RemoveStopWords(local_data))\n",
    "    df[local_data] = df[local_data].apply(lambda local_data: Lemmatization(local_data))\n",
    "    df[local_data] = df[local_data].apply(lambda local_data: remove_extra_spaces(local_data))\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pre_processing(reviews_df,'review')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reviews_df.review\n",
    "y = reviews_df.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(1,1))\n",
    "X_count   = count_vec.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfTransformer()\n",
    "X_freq_count = tf.fit_transform(X_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_freq_count,y,test_size=0.8,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Classifier test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(alpha=0.1,hidden_layer_sizes=(20,),activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rícharde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.1, hidden_layer_sizes=(20,))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.1, hidden_layer_sizes=(20,))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=0.1, hidden_layer_sizes=(20,))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7895065584009994"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.782860824742268"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando os resultados realizando como pré-processamento a retirada de Stop Words, pontuações/carcteres especiais e tokenização tivemos um F1 de 0.7302 com o melhor modelo dentre os testados (RandomForest). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No segundo pré-processamento aplicamos a expansão das contrações, colocamos o texto em caixa baixa, fizemos a remoção de pontuações e caracteres especiais, remoção de Stop Words, Lematização e remoção de possíveis espaços extras. Com esse novo pré-processamento, tivemos como resultado de F1-Score no Random Forest o valor ded 0.7378. Podemos constar que mesmo aplicando as novas técnicas de pré-processamento descritas a melhora na classificação foi irrisória"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43241d3e6bb1972c551f4c6aa4b3e6bb2f4e84c18abfcaae8493a58a132971b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
